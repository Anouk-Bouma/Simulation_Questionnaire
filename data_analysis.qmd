---
title: "data_analysis"
format: html
editor: visual
---

<!--# Hey bestie, before submitting the final version -> ctrl + f: 'NOTE' to check if all notes are evaluated and removed -->

## Version Control

```{r}
renv::restore()

library(tidyverse)
library(readxl)
library(ggplot2)
library(stringr)
library(purrr)
library(writexl)
library(openxlsx)
library(forcats)
library(egg)
library(ggpubr)
```

## Loading the data

```{r}

# Load the cleaned data here
load("survey_data_cleaned.RData")

# Load questionnaire metadata
meta <- read.xlsx("question_labels.xlsx", sheet = "codebook")
```

## Sample sizes per question

```{r}

sample_sizes <- meta %>%
  distinct(question_group, question_code) %>%
  arrange(question_group) %>%
  group_by(question_group) %>%
  summarise(
    sample_col = {
      counts <- sapply(question_code, function(col) {
        sum(!is.na(data[[col]]))
      })
      question_code[which(counts > 0)[1]]
    },
    n = {
      counts <- sapply(question_code, function(col) {
        sum(!is.na(data[[col]]))
      })
      counts[which(counts > 0)[1]]
    },
    .groups = "drop"
  )
```

## Descriptives table

```{r}

#' Title
#'
#' @param data dataset containing the respondent survey data
#' @param metadata dataset containing metadata about the survey including question numbers, answer categories and variable names.
#' @param sample_sizes a dataframe containing the sample size per question
#'
#' @returns
#'
#' @examples
create_question_table <- function(data, metadata, sample_sizes) {

  all_tables <- list()

  # Ensure metadata$value is numeric so it can be joined later
  metadata <- metadata %>%
    mutate(value = suppressWarnings(as.numeric(value)))
  
  # Loops over every question: question_group is a question (e.g., Q7a)
  for (question in unique(metadata$question_group)) {

    # Metadata for this question
    meta_group <- metadata %>%
      filter(question_group == question) %>% # 'question' is the loop index
      arrange(order)
    
    # Take order index for this question
    q_order <- unique(meta_group$question_order)

    # Get sample size for this question
    sample_n <- sample_sizes %>%
      filter(question_group == question) %>%
      pull(n)

    # MULTI-SELECT QUESTION -----------------------------------------
    if (n_distinct(meta_group$question_code) > 1) { # check if multi-select
      
      # Identify columns in participant data for this question and extract
      option_cols <- meta_group$question_code
      subdata <- data[, option_cols]
      #answered <- rowSums(!is.na(subdata)) > 0 #NOTE: delete line?

      tbl <- subdata %>%
        summarise(across(all_of(option_cols), 
                         ~ sum(.x == 1, na.rm = TRUE))) %>%
        pivot_longer(
          cols = everything(),
          names_to = "question_code",
          values_to = "N"
        ) %>%
        # add metadata (answer labels to data)
        left_join(meta_group, by = "question_code") %>%
        mutate(
          Question = question,
          question_order = q_order,
          sample_size = sample_n
        ) %>%
        select(Question, 
               question_order,
               variable_name,
               answer_label, 
               N, 
               sample_size, 
               order)

      all_tables[[question]] <- tbl
      
    } else {

      # SINGLE-SELECT QUESTION ---------------------------------------
      qcol <- meta_group$question_code[1]
      data[[qcol]] <- suppressWarnings(as.numeric(data[[qcol]]))

      tbl <- meta_group %>%
        select(value, variable_name, answer_label, order) %>%
        left_join(
          data %>%
            filter(!is.na(.data[[qcol]])) %>%
            group_by(value = .data[[qcol]]) %>%
            summarise(N = n(), .groups = "drop"),
          by = "value"
        ) %>%
        mutate(
          N = replace_na(N, 0),
          Question = question,
          question_order = q_order,
          sample_size = sample_n
        ) %>%
        select(Question, 
               question_order,
               variable_name,
               answer_label, 
               N, 
               sample_size, 
               order)

      all_tables[[question]] <- tbl
      
    }
  }

  # Bind all rows
  result <- bind_rows(all_tables) %>%
    arrange(question_order, order) %>%
    select(-order)

  # ---- NEW: calculate Percentage at the very end ----
  result <- result %>%
    mutate(
      Percentage = ifelse(
        sample_size == 0, 0, round(N / sample_size * 100, 1))
    ) %>%
    mutate(
      N_percentage = paste0(N, " (", Percentage, "%)")
    ) %>%
    # drop column question_order from dataframe
    select(!question_order)

  result
}


descriptives_table <- create_question_table(data, meta, sample_sizes)

```

## Save table for use in paper

```{r}

write.xlsx(descriptives_table, file = "test_table_desc.xlsx")
```

## Descriptives continues variables

```{r}

vars <- c("Q1", "Q27_1", "Q28_1", "Q29_1")

# Create an empty dataframe to fill
descriptives_continues <- data.frame(
  variable = vars,
  mean = NA_real_,
  sd = NA_real_,
  n = NA_integer_,
  stringsAsFactors = FALSE
)

# Loop through variables and fill the table
for (i in seq_along(vars)) {
  v <- vars[i]
  
  # extract variable and recode -99 and 999 to NA
  x <- data[[v]]
  x[x %in% c(-99, 999)] <- NA
  
  # fill values
  descriptives_continues$mean[i] <- mean(x, na.rm = TRUE)
  descriptives_continues$sd[i]   <- sd(x, na.rm = TRUE)
  descriptives_continues$n[i]    <- sum(!is.na(x))
}

descriptives_continues
  
```

## Correlations

```{r}

vars <- c("Q1", "Q27_1", "Q28_1", "Q29_1")

# Extract only the chosen variables
vars_for_correlations <- data[vars]

# Change missing values to NA (-99 and 999)
vars_for_correlations[vars_for_correlations == -99] <- NA
vars_for_correlations[vars_for_correlations == 999] <- NA

# Compute pairwise correlations using pairwise complete observations
cor_matrix <- cor(vars_for_correlations, use = "pairwise.complete.obs")

cor_matrix

#write.xlsx(cor_matrix, "cor_matrix.xlsx")


 # ----------- NOTE: not done yet here: --------- #

# Calculating the t-statistic with the finite population correction factor
r <- 0.3341475
rho <- 0
n <- 196
N <- 949 # Number of included articles (= population size)

t_corrected <- function(r, rho, n, N) {
  t <- (r - rho)/(sqrt((1-r^2)/(n - 2))*sqrt((N-n)/(N-1)))
  return(t)
}

# two-sided t-test
p_value <- function(t_value, df) { 2 * (1 - pt(abs(t_value), df)) }


# Run the t-test
t_value <- t_corrected(r, rho, n, N)
p <- p_value(t_value, df = n - 2)

```

## Plotting

For every question, there have to be the following plots:

-   Frequencies overall

-   Frequencies split over neutral/non-neutral

-   Make option in function to split by a specific variable (ideally plotted in the same graph). And make an option to select freqencies or percentages in the function.

-   a/b versions of the same question should also be in combined plots

-   n in the title of the plots

## One combined function for all plots

```{r}
plot_combined_questions <- function(
  data,
  metadata,
  combined_questions,
  legend_labels = c("Conditions", "Methods", "Performance Measures"),
  title_plot = combined_questions,
  combine_ab = FALSE,
  wrap_width = 50,
  colors = c("#0072B2", "#D55E00", "#F0E442"),
  y_max = 100,
  show_legend = length(combined_questions) > 1
) {

  # ---- 1. Select & (optionally) map a/b versions ----
  if (combine_ab) {

    question_map <- tibble(
      combined = rep(combined_questions, each = 2),
      question_group = paste0(rep(combined_questions, each = 2), c("a", "b"))
    )

    meta_sel <- metadata %>%
      inner_join(question_map, by = "question_group") %>%
      arrange(combined, order)

  } else {

    meta_sel <- metadata %>%
      filter(question_group %in% combined_questions) %>%
      mutate(combined = question_group) %>%
      arrange(combined, order)
  }

  # ---- 2. Sample sizes (who SAW the question) ----
  if (combine_ab) {

    sample_sizes_ab <- meta_sel %>%
      distinct(combined, question_group, question_code) %>%
      group_by(combined, question_group) %>%
      summarise(
        n = sum(rowSums(!is.na(data[question_code])) > 0),
        .groups = "drop"
      )

    sample_sizes <- sample_sizes_ab %>%
      group_by(combined) %>%
      summarise(sample_size = sum(n), .groups = "drop")

  } else {

    sample_sizes <- meta_sel %>%
      distinct(combined, question_code) %>%
      group_by(combined) %>%
      summarise(
        sample_size = sum(!is.na(data[[first(question_code)]])),
        .groups = "drop"
      )
  }

  # ---- 3. Count selections ----
  long_data <- data %>%
    pivot_longer(
      cols = unique(meta_sel$question_code),
      names_to = "question_code",
      values_to = "value"
    )

  if (combine_ab) {
    long_data <- long_data %>% filter(value == 1)
  } else {
    long_data <- long_data %>% filter(!is.na(value))
  }

  counts <- meta_sel %>%
    select(combined, question_code, short_label, order, value) %>%
    left_join(
      long_data %>%
        count(question_code, value, name = "freq"),
      by = c("question_code", "value")
    ) %>%
    mutate(freq = replace_na(freq, 0)) %>%
    group_by(combined, short_label, order) %>%
    summarise(freq = sum(freq), .groups = "drop")

  # ---- 4. Percentages & factors ----
  plot_data <- counts %>%
    left_join(sample_sizes, by = "combined") %>%
    mutate(
      pct = 100 * freq / sample_size,
      label = sprintf("%.1f%% (%d)", pct, freq),
      combined = factor(combined, levels = combined_questions),
      short_label = factor(
        short_label,
        levels = meta_sel %>%
          arrange(order) %>%
          distinct(short_label) %>%
          pull(short_label)
      )
    )

  # ---- 5. Plot ----
  ggplot(
    plot_data,
    aes(
      x = fct_rev(short_label),
      y = pct,
      fill = combined
    )
  ) +
    geom_col(
      position = position_dodge(width = 0.8),
      width = 0.8,
      alpha = 0.8,
      color = "black",
      linewidth = 0.3
    ) +
    geom_text(
      aes(label = label),
      position = position_dodge(width = 0.8),
      hjust = -0.05,
      size = 3.5
    ) +
    coord_flip() +
    scale_y_continuous(
      limits = c(0, y_max),
      expand = expansion(mult = c(0, 0.1))
    ) +
    scale_fill_manual(
      values = setNames(colors, combined_questions),
      labels = setNames(legend_labels, combined_questions),
      name = ""
    ) +
    scale_x_discrete(
      labels = ~ stringr::str_wrap(.x, wrap_width)
    ) +
    labs(
      x = NULL,
      y = "Percentage",
      title = if (!is.null(title_plot)) stringr::str_wrap(title_plot, wrap_width)
    ) +
    theme_bw() +
    theme(
      plot.title = element_text(hjust = 0.5, size = 10, face = "bold"),
      axis.title.x = element_text(size = 8),
      axis.text.y = element_text(hjust = 1, size = 8, face = "bold"),
      legend.position = if (show_legend) "right" else "none"
    )
}

```

## All Plots

```{r}

# Section 2: Reporting

# Plot for question 5, 8 and 11

p5_8_11 <- plot_combined_questions(data,
                               meta,
                               combined_questions = c("Q5", "Q8", "Q11"),
                               combine_ab = FALSE,
                               title_plot = "Is at least one result reported for every condition/method/performance measure that was part of the simulations?",
                               y_max = 100,
                               wrap_width = 80)

# Plot for question 6, 9, and 12

p6_9_12 <- plot_combined_questions(data,
                               meta,
                               combined_questions = c("Q6", "Q9", "Q12"),
                               combine_ab = FALSE,
                               title_plot = "Does the body of the paper report at least one result for every [Legend]",
                               y_max = 100,
                               wrap_width = 80)


# Plot for question 7, 10, and 13

p7_10_13 <- plot_combined_questions(data,
                               meta,
                               combined_questions = c("Q7", "Q10", "Q13"),
                               combine_ab = TRUE,
                               title_plot = "Results weren't reported for all [Legend] because...",
                               y_max = 100,
                               wrap_width = 80)


# split_combined <- ggarrange(p5_8_11, p6_9_12, nrow = 2)
# ggarrange(split_combined, p7_10_13, nrow = 1)




# Topic 2.4: Missing values/nonconvergence
p16 <- plot_combined_questions(data,
                               meta,
                               combined_questions = "Q16",
                               combine_ab = TRUE,
                               colors = "#D55E00",
                               title_plot = "The number of missing values/nonconvergent iterations wasn't reported because...",
                               y_max = 75,
                               wrap_width = 80)

# Topic 2.5: MCSE
p18 <- plot_combined_questions(data, 
                        meta, 
                        combined_questions = "Q18", 
                        combine_ab = TRUE, 
                        colors = "#D55E00",
                        title_plot = "MCSE's weren't reported (for all results) because...",
                        y_max = 75,
                        wrap_width = 80) 

# Topic 2.6: Guidelines
p20 <- plot_combined_questions(data, 
                        meta, 
                        combined_questions = "Q20", 
                        combine_ab = FALSE, 
                        colors = "#D55E00",
                        title_plot = "Why was no research guideline used?",
                        y_max = 75,
                        wrap_width = 80)

# Topic 2.7: Preregistration
p22 <- plot_combined_questions(data, 
                        meta, 
                        combined_questions = "Q22", 
                        combine_ab = FALSE, 
                        colors = "#D55E00",
                        title_plot = "Why wasn't the simulation study preregistered?",
                        y_max = 75,
                        wrap_width = 80) 

# Topic 2.8: Open code
p24 <- plot_combined_questions(data, 
                        meta, 
                        combined_questions = "Q24", 
                        combine_ab = FALSE, 
                        colors = "#D55E00",
                        title_plot = "Why is not all code openly available?",
                        y_max = 100,
                        wrap_width = 80)

# Topic 2.9: Open code
p25 <- plot_combined_questions(data, 
                        meta, 
                        combined_questions = "Q25", 
                        combine_ab = FALSE, 
                        colors = "#D55E00",
                        title_plot = "Which measures were taken for computational reproducibility?",
                        y_max = 100,
                        wrap_width = 80)

ggarrange(p20, p24, p22, p25, nrow = 2, ncol = 2)
ggarrange(p16, p18, nrow = 1, ncol = 2)

```

## 
