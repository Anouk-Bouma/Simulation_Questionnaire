---
title: "data_analysis"
format: html
editor: visual
---

<!--# Hey bestie, before submitting the final version -> ctrl + f: 'NOTE' to check if all notes are evaluated and removed -->

## Dependency Management

```{r}
renv::restore()

library(tidyverse)
library(readxl)
library(ggplot2)
library(stringr)
library(purrr)
library(writexl)
library(openxlsx)
library(forcats)
library(egg)
library(ggpubr)
library(reshape2)
library(lsr)
library(gridExtra)
library(psych)
```

## 1. Loading the data

```{r}

# Load the cleaned data here
load("survey_data_cleaned.RData")

# Load questionnaire metadata
meta <- read.xlsx("question_labels.xlsx", sheet = "codebook")
```

## 2. General functions and objects

Here, some general functions objects and transformations are conducted that are necessary to run the other blocks of code. In principle, after running each of these general blocks, can be run separately from one another. NOTE: check if this works in the end.

### 2.1 Data transformation

Here, we add three variables to the dataset that combine the two selective reporting questions for conditions, methods, and performance measures.

```{r}

data <- data %>%
  mutate(conditions = ifelse(is.na(Q6) & Q5 == 2, 0, Q6),
         methods = ifelse(is.na(Q9) & Q8 == 2, 0, Q9),
         perfmeas = ifelse(is.na(Q12) & Q11 == 2, 0, Q12)) %>%
  # Making sure -99 values are NA
  mutate(conditions = ifelse(conditions == -99, NA_real_, conditions),
         methods = ifelse(methods == -99, NA_real_, methods),
         perfmeas = ifelse(perfmeas == -99, NA_real_, perfmeas))

```

### 2.2 Sample sizes per question

```{r}

sample_sizes <- meta %>%
  distinct(question_group, question_code) %>%
  arrange(question_group) %>%
  group_by(question_group) %>%
  summarise(
    sample_col = {
      counts <- sapply(question_code, function(col) {
        sum(!is.na(data[[col]]) & data[[col]] != -99 & data[[col]] != 999)
      })
      question_code[which(counts > 0)[1]]
    },
    n = {
      counts <- sapply(question_code, function(col) {
        sum(!is.na(data[[col]]) & data[[col]] != -99 & data[[col]] != 999)
      })
      counts[which(counts > 0)[1]]
    },
    .groups = "drop"
  )

```

### 2.3 Objects that are used across codeblocks

```{r}

# Vector of all nominal variables
all_vars <- c("conditions", "Q7", "methods", "Q10", "perfmeas", "Q13", "Q14", "Q15", "Q16", "Q17", "Q18", "Q19", "Q20", "Q21", "Q22", "Q23", "Q24", "Q25")

# Vector of nominal variables that have an a and a b version
vars_to_plot_ab <- c("Q7", "Q10", "Q13", "Q16", "Q18")

# Vector of nominal variables without versions
vars_to_plot_regular <- c("conditions", "methods", "perfmeas", "Q14", "Q15", "Q17", "Q19", "Q20", "Q21", "Q22", "Q23", "Q24", "Q25")

```

## 3. Analyses

### 3.1 Descriptives categorical variables

```{r}

#' Title
#'
#' @param data dataset containing the respondent survey data
#' @param metadata dataset containing metadata about the survey including question numbers, answer categories and variable names.
#' @param sample_sizes a dataframe containing the sample size per question
#'
#' @returns
#'
#' @examples
create_question_table <- function(data, metadata, sample_sizes) {

  all_tables <- list()

  # Ensure metadata$value is numeric so it can be joined later
  metadata <- metadata %>%
    mutate(value = suppressWarnings(as.numeric(value)))
  
  # Loops over every question: question_group is a question (e.g., Q7a)
  for (question in unique(metadata$question_group)) {

    # Metadata for this question
    meta_group <- metadata %>%
      filter(question_group == question) %>% # 'question' is the loop index
      arrange(order)
    
    # Take order index for this question
    q_order <- unique(meta_group$question_order)

    # Get sample size for this question
    sample_n <- sample_sizes %>%
      filter(question_group == question) %>%
      pull(n)

    # MULTI-SELECT QUESTION -----------------------------------------
    if (n_distinct(meta_group$question_code) > 1) { # check if multi-select
      
      # Identify columns in participant data for this question and extract
      option_cols <- meta_group$question_code
      subdata <- data[, option_cols]
      #answered <- rowSums(!is.na(subdata)) > 0 #NOTE: delete line?

      tbl <- subdata %>%
        summarise(across(all_of(option_cols), 
                         ~ sum(.x == 1, na.rm = TRUE))) %>%
        pivot_longer(
          cols = everything(),
          names_to = "question_code",
          values_to = "N"
        ) %>%
        # add metadata (answer labels to data)
        left_join(meta_group, by = "question_code") %>%
        mutate(
          Question = question,
          question_order = q_order,
          sample_size = sample_n
        ) %>%
        select(Question, 
               question_order,
               variable_name,
               answer_label, 
               N, 
               sample_size, 
               order)

      all_tables[[question]] <- tbl
      
    } else {

      # SINGLE-SELECT QUESTION ---------------------------------------
      qcol <- meta_group$question_code[1]
      data[[qcol]] <- suppressWarnings(as.numeric(data[[qcol]]))

      tbl <- meta_group %>%
        select(value, variable_name, answer_label, order) %>%
        left_join(
          data %>%
            filter(!is.na(.data[[qcol]])) %>%
            group_by(value = .data[[qcol]]) %>%
            summarise(N = n(), .groups = "drop"),
          by = "value"
        ) %>%
        mutate(
          N = replace_na(N, 0),
          Question = question,
          question_order = q_order,
          sample_size = sample_n
        ) %>%
        select(Question, 
               question_order,
               variable_name,
               answer_label, 
               N, 
               sample_size, 
               order)

      all_tables[[question]] <- tbl
      
    }
  }

  # Bind all rows
  result <- bind_rows(all_tables) %>%
    arrange(question_order, order) %>%
    select(-order)

  # ---- NEW: calculate Percentage at the very end ----
  result <- result %>%
    mutate(
      Percentage = ifelse(
        sample_size == 0, 0, round(N / sample_size * 100, 1))
    ) %>%
    mutate(
      N_percentage = paste0(N, " (", Percentage, "%)"),
      Variable = paste0(variable_name, " (", Question, ")")
    ) %>%
    # drop column question_order from dataframe
    select(!question_order)

  result
}


descriptives_table <- create_question_table(data, meta, sample_sizes)

# Saving table for use in paper
#write.xlsx(descriptives_table, file = "test_table_desc.xlsx")

```

### 3. 2 Descriptives continues variables

```{r}

vars <- c("Q1", "Q27_1", "Q28_1", "Q29_1")

# Create an empty dataframe to fill
descriptives_continues <- data.frame(
  variable = vars,
  mean = NA_real_,
  sd = NA_real_,
  n = NA_integer_,
  stringsAsFactors = FALSE
)

# Loop through variables and fill the table
for (i in seq_along(vars)) {
  v <- vars[i]
  
  # extract variable and recode -99 and 999 to NA
  x <- data[[v]]
  x[x %in% c(-99, 999)] <- NA
  
  # fill values
  descriptives_continues$mean[i] <- mean(x, na.rm = TRUE)
  descriptives_continues$sd[i]   <- sd(x, na.rm = TRUE)
  descriptives_continues$n[i]    <- sum(!is.na(x))
}

descriptives_continues

# NOTE: add saving function here too?
  
```

### 3.3 Correlations

```{r}

vars <- c("Q1", "Q27_1", "Q28_1", "Q29_1")

# Extract only the chosen variables
vars_for_correlations <- data[vars]

# Change missing values to NA (-99 and 999)
vars_for_correlations[vars_for_correlations == -99] <- NA
vars_for_correlations[vars_for_correlations == 999] <- NA

# Compute pairwise correlations using pairwise complete observations
cor_matrix <- cor(vars_for_correlations, use = "pairwise.complete.obs")


##-- Correlation t-tests with finite sample correction --##

# Create a matrix of non-missing counts for each pair
n_matrix <- crossprod(!is.na(vars_for_correlations))

# Input numbers
rho <- 0 # test against 0
N <- 949 # number of included articles

# Calculate t-values for the whole matrix
t_matrix <- (cor_matrix - rho) / (sqrt((1 - cor_matrix^2) / (n_matrix - 2)) * sqrt((N - n_matrix) / (N - 1)))

# Calculate p-values
p_matrix <- 2 * (1 - pt(abs(t_matrix), df = n_matrix - 2))

# Clean up diagonals
diag(p_matrix) <- NA
diag(t_matrix) <- NA

# Combine into single data frame
results <- data.frame(
  Pair = melt(cor_matrix)$Var1,
  Var2 = melt(cor_matrix)$Var2,
  Correlation = melt(cor_matrix)$value,
  t_stat = melt(t_matrix)$value,
  p_val = melt(p_matrix)$value,
  n = melt(n_matrix)$value
)

results <- results %>%
  mutate(df = n - 2)

# Filter out duplicates (only keep one diagonal)
results <- results[as.numeric(results$Pair) < as.numeric(results$Var2), ]

# Calculating confidence intervals
conf_level <- 0.95
alpha <- 1 - conf_level
z_crit <- qnorm(1 - alpha/2)

# Apply Fisher Z transformation and finite population correction factor-adjusted SE
results <- results %>%
    mutate(
        # Fisher z transformation of the correlation
        fisher_z = 0.5 * log((1 + Correlation) / (1 - Correlation)),
        
        # Standard Error for Fisher z with Finite Population Correction
        se_fpc = (1 / sqrt(n - 3)) * sqrt((N - n) / (N - 1)),
        
        # Calculate Lower and Upper bounds in Z values
        lower_z = fisher_z - (z_crit * se_fpc),
        upper_z = fisher_z + (z_crit * se_fpc),
        
        # Back-transform to Correlation
        CI_lower = (exp(2 * lower_z) - 1) / (exp(2 * lower_z) + 1),
        CI_upper = (exp(2 * upper_z) - 1) / (exp(2 * upper_z) + 1)
    ) %>%
    # Clean up unnecessary columns
    select(-fisher_z, -se_fpc, -lower_z, -upper_z)


# Saving the results
#write.xlsx(results, "correlation_results.xlsx")

### Scatterplots
# NOTE: would need to put names in the plot for clarity: maybe change names also for calculations above 
pairs(~Q27_1 + Q28_1 + Q29_1, data = data, xlim = c(0,1), ylim = c(0,1))


```

### 3.4 Calculating Fisher's Exact test, Chi\^2, and Cramer's V for split by new_method

1.  Get dataframe as input for both the plots and the calculations \# NOTE

```{r}
# NOTE: change name of plot-data. because it is not used to plot anymore
get_plot_data <- function(data, metadata, combined_questions, split_var, combine_ab = FALSE) {
  
  # ---- 1. Select & Map Metadata ----
  if (combine_ab) {
    question_map <- tibble(
      combined = rep(combined_questions, each = 2),
      question_group = paste0(rep(combined_questions, each = 2), c("a", "b"))
    )
    meta_sel <- metadata %>%
      inner_join(question_map, by = "question_group") %>%
      arrange(combined, order)
  } else {
    meta_sel <- metadata %>%
      filter(question_group %in% combined_questions) %>%
      mutate(combined = question_group) %>%
      arrange(combined, order)
  }

  # ---- 2. Calculate Sample Sizes per Group ----
  plot_sample_sizes <- meta_sel %>%
    distinct(combined, question_group, question_code) %>%
    group_by(combined, question_group) %>%
    group_modify(~ {
      current_code <- .x$question_code[1]
      data %>%
        # Ensure split_var is a factor here
        mutate(across(all_of(split_var), as.factor)) %>% 
        group_by(across(all_of(split_var))) %>%
        summarise(
          sample_size = sum(!is.na(.data[[current_code]]) & 
                            .data[[current_code]] != -99 & 
                            .data[[current_code]] != 999),
          .groups = "drop"
        )
    }) %>%
    ungroup()

  if (combine_ab) {
    plot_sample_sizes <- plot_sample_sizes %>%
      group_by(across(all_of(c(split_var, "combined")))) %>%
      summarise(sample_size = sum(sample_size), .groups = "drop")
  } else {
    plot_sample_sizes <- plot_sample_sizes %>%
      select(all_of(c(split_var, "combined", "sample_size")))
  }

  # ---- 3. Count Selections ----
  relevant_codes <- unique(meta_sel$question_code)
  long_data <- data %>%
    select(all_of(c(split_var, relevant_codes))) %>%
    # Ensure split_var is a factor here as well
    mutate(across(all_of(split_var), as.factor)) %>%
    pivot_longer(
      cols = all_of(relevant_codes),
      names_to = "question_code",
      values_to = "value"
    )

  if (combine_ab) {
    long_data <- long_data %>% filter(value == 1)
  } else {
    long_data <- long_data %>% filter(!is.na(value))
  }

  counts <- long_data %>%
    inner_join(meta_sel, by = c("question_code", "value")) %>%
    group_by(across(all_of(c(split_var, "combined", "short_label", "order")))) %>%
    summarise(freq = n(), .groups = "drop")

  # ---- 4. Percentages & Factors ----
  plot_data <- counts %>%
    complete(
      nesting(combined, short_label, order), 
      !!sym(split_var), 
      fill = list(freq = 0)
    ) %>%
    left_join(plot_sample_sizes, by = c(split_var, "combined")) %>%
    mutate(
      pct = ifelse(is.na(sample_size) | sample_size == 0, 0, 100 * freq / sample_size),
      label = sprintf("%.1f%% (%d)", pct, freq),
      short_label = factor(
        short_label, 
        levels = meta_sel %>% arrange(order) %>% distinct(short_label) %>% pull(short_label)
      )
    )
  
  return(plot_data)
}

```

Apply function to generate the dataframe for new_method

```{r}

# Run the get plot data function to generate the dataframe
plot_data_1 <- get_plot_data(data = data, metadata = meta, combined_questions = vars_to_plot_ab, split_var = "new_method", combine_ab = TRUE)

plot_data_2 <- get_plot_data(data = data, metadata = meta, combined_questions = vars_to_plot_regular, split_var = "new_method", combine_ab = FALSE)

plot_data <- rbind(plot_data_1, plot_data_2)

```

2.  Take the processed plot_data and run the tests

```{r}
 calculate_stats_by_question <- function(plot_df, split_var) {
  
  questions <- unique(plot_df$combined)
  results_list <- list()
  
  # number of iterations
  iterations <- 100000
  
  for (q in questions) {
    q_data <- plot_df %>% filter(combined == q)
    
    test_table <- q_data %>%
      select(short_label, all_of(split_var), freq) %>%
      pivot_wider(names_from = all_of(split_var), values_from = freq) %>%
      mutate(across(everything(), ~replace_na(., 0))) %>%
      column_to_rownames("short_label") %>%
      as.matrix()
    
    # Run Fisher's Exact Test
    fisher_res <- fisher.test(test_table, simulate.p.value = TRUE, B = iterations)
    
    # --- MCSE CALCULATION ---
    p_val <- fisher_res$p.value
    # Formula as defined by Morris et al. (2019) for proportion estimates:
    mcse_val <- sqrt((p_val * (1 - p_val)) / iterations)
    # ------------------------
    
    chi_res <- chisq.test(test_table)
    cv_res  <- lsr::cramersV(test_table)
    
    results_list[[q]] <- list(
      question = q,
      table = test_table,
      fisher_p = p_val,
      fisher_mcse = mcse_val,
      chi_sq = chi_res$statistic,
      chi_p = chi_res$p.value,
      cramers_v = cv_res
    )
  }
  
  return(results_list)
}

all_results <- calculate_stats_by_question(plot_data, "new_method")

summary_stats <- do.call(rbind, lapply(all_results, function(x) {
  data.frame(
    Question     = x$question,
    Fisher_P     = round(x$fisher_p, 4),
    Fisher_MCSE  = round(x$fisher_mcse, 5),
    Chi_Sq       = round(x$chi_sq, 2),
    Chi_P        = round(x$chi_p, 4),
    Cramers_V    = round(x$cramers_v, 3),
    Significance = ifelse(x$fisher_p < 0.05, "Yes*", "No")
  )
}))


#write.xlsx(summary_stats, "contingency_tests.xlsx")
```

### 3.5 Cronbach's alpha

```{r}

# Select Evaluative variables
alpha_data <- data %>%
  select(Q27_1, Q28_1, Q29_1)

# Make missings missings
alpha_data[alpha_data == -99] <- NA
alpha_data[alpha_data == 999] <- NA

# Cronbach's alpha
alpha(alpha_data)

```

## 4. Plotting

### 4.1 One combined function for all plots

In this block the function is defined that can be used to plot all general plots. For the plots that are split between a variable, another function is later defined.

```{r}
plot_combined_questions <- function(
        data,
        metadata,
        sample_sizes,
        combined_questions,
        legend_labels = c("Performance Measures", "Methods", "Conditions"),
        title_plot = combined_questions,
        combine_ab = FALSE,
        wrap_width = 50,
        colors = c("#F0E442", "#D55E00", "#0072B2"),
        y_max = 100,
        show_legend = length(combined_questions) > 1
) {
    
    # ---- 1. Select & map  ----
    if (combine_ab) {
        question_map <- tibble(
            combined = rep(combined_questions, each = 2),
            question_group = paste0(rep(combined_questions, each = 2), c("a", "b"))
        )
        meta_sel <- metadata %>%
            inner_join(question_map, by = "question_group") %>%
            arrange(combined, order)
    } else {
        meta_sel <- metadata %>%
            filter(question_group %in% combined_questions) %>%
            mutate(combined = question_group) %>%
            arrange(combined, order)
    }
    
    # ---- 2. Sample Sizes ----
    if (combine_ab) {
        plot_sample_sizes <- sample_sizes %>%
            inner_join(question_map, by = "question_group") %>%
            group_by(combined) %>%
            summarise(sample_size = sum(n), .groups = "drop")
    } else {
        plot_sample_sizes <- sample_sizes %>%
            filter(question_group %in% combined_questions) %>%
            rename(combined = question_group, sample_size = n) %>%
            select(combined, sample_size)
    }
    
    # ---- 3. Count selections ----
    long_data <- data %>%
        pivot_longer(
            cols = any_of(unique(meta_sel$question_code)),
            names_to = "question_code",
            values_to = "value"
        )
    
    if (combine_ab) {
        long_data <- long_data %>% filter(value == 1)
    } else {
        long_data <- long_data %>% filter(!is.na(value))
    }
    
    counts <- meta_sel %>%
        select(combined, question_code, short_label, order, value) %>%
        left_join(
            long_data %>%
                count(question_code, value, name = "freq"),
            by = c("question_code", "value")
        ) %>%
        mutate(freq = replace_na(freq, 0)) %>%
        group_by(combined, short_label, order) %>%
        summarise(freq = sum(freq), .groups = "drop")
    
    # ---- 4. Percentages & factors ----
    plot_data <- counts %>%
        left_join(plot_sample_sizes, by = "combined") %>% 
        mutate(
            pct = 100 * freq / sample_size,
            label = sprintf("%.1f%% (%d)", pct, freq),
            # Keep combined in original order for the legend
            combined = factor(combined, levels = combined_questions),
            # Reverse short_label levels so the first metadata item is the 'highest' factor level
            short_label = factor(
                short_label,
                levels = rev(unique(meta_sel$short_label[order(meta_sel$order)]))
            )
        )
    
    # ---- 5. Plot ----
    ggplot(
        plot_data,
        aes(
            x = short_label, # Factor levels already reversed in Step 4
            y = pct,
            fill = combined
        )
    ) +
        geom_col(
            position = position_dodge(width = 0.8),
            width = 0.8,
            alpha = 0.8,
            color = "black",
            linewidth = 0.3
        ) +
        geom_text(
            aes(label = label),
            position = position_dodge(width = 0.8),
            hjust = -0.1,
            size = 3.5
        ) +
        scale_fill_manual(
            values = setNames(colors, combined_questions),
            labels = setNames(legend_labels, combined_questions),
            name = "" 
        ) +
        coord_flip(
        ) +
        scale_y_continuous(
            limits = c(0, y_max),
            breaks = seq(0, y_max + 10, by = 20),
            expand = expansion(mult = c(0, 0.15))
        ) +
        scale_x_discrete(
            labels = ~ stringr::str_wrap(.x, wrap_width)
        ) +
        guides(
            # Reverse the legend so the 'top' bar matches the 'top' legend item
            fill = guide_legend(reverse = TRUE)
        ) +
        labs(
            x = NULL,
            y = "Percentage",
            title = if (!is.null(title_plot)) stringr::str_wrap(title_plot, wrap_width)
        ) +
        theme_bw() +
        theme(
            plot.title = element_text(hjust = 0.5, size = 12, face = "bold"),
            axis.title.x = element_text(size = 8),
            axis.text.y = element_text(hjust = 1, size = 9, face = "bold"),
            legend.position = if (show_legend) "right" else "none",
            panel.grid.major.y = element_blank(),
            panel.grid.minor.y = element_blank(),
            panel.grid.minor.x = element_blank()
        )
}
```

### 4.2 All Plots

```{r}

########## Figure 2 ##########
#Selective Reporting of Conditions, Methods, and Performance Measures
p_freq_selective_reporting <- plot_combined_questions(data = data,
                               meta,
                               sample_sizes = sample_sizes,
                               combined_questions = c("perfmeas", "methods", "conditions"), # reversed order because of how ggplot handles coordflip, important that order is the same as legend specified in plotting function
                               combine_ab = FALSE,
                               title_plot = "Is at least one result reported for every condition/method/performance measure that was part of the simulations?",
                               y_max = 90,
                               wrap_width = 80)

ggsave("Figure_2.png", plot = p_freq_selective_reporting, width = 16.66*1.5, height = 6.65*1.5, units = "cm", dpi = 300)

# --------------------------------


########## Figure 3 ###########
# Rationale for Selective Reporting of Conditions, Methods, and Performance Measures
p_rationale_selective_reporting <- plot_combined_questions(data,
                               meta,
                               combined_questions = c("Q13", "Q10", "Q7"), # reversed order because of how ggplot handles coordflip, important that order is the same as legend specified in plotting function
                               sample_sizes = sample_sizes,
                               combine_ab = TRUE,
                               title_plot = "Results weren't reported for all conditions/methods/performance measures (in the body of the paper) because of...",
                               y_max = 90,
                               wrap_width = 65)

ggsave("Figure_3.png", plot = p_rationale_selective_reporting, width = 14.66*1.5, height = 14.5*1.5, units = "cm", dpi = 300)

# -------------------------------


########## Figure 5 ############
# Panel A
# Topic 2.4: Missing values/nonconvergence
p_rationale_missings <- plot_combined_questions(data,
                               meta,
                               combined_questions = "Q16",
                               sample_sizes = sample_sizes,
                               combine_ab = TRUE,
                               colors = "#D55E00",
                               title_plot = "The number of missing values/nonconvergent iterations wasn't reported (for all methods and conditions) because of...",
                               y_max = 70,
                               wrap_width = 60)

# Panel B
# Topic 2.5: MCSE
p_rationale_MCSE <- plot_combined_questions(data, 
                        meta, 
                        combined_questions = "Q18",
                        sample_sizes = sample_sizes,
                        combine_ab = TRUE, 
                        colors = "#D55E00",
                        title_plot = "MCSEs weren't reported (for all results) because of...",
                        y_max = 70,
                        wrap_width = 80) 

p_rationale_missings <- p_rationale_missings + theme(plot.margin = margin(10, 10, 10, 30))
p_rationale_MCSE <- p_rationale_MCSE + theme(plot.margin = margin(10, 10, 10, 30))

arrange_fig5 <- ggarrange(p_rationale_missings, p_rationale_MCSE, nrow = 2, ncol = 1, labels = "AUTO")
ggsave("Figure_5.png", plot = arrange_fig5, width = 14.66*1.5, height = 14.05*1.5, units = "cm", dpi = 300)


# ------------------------------




########### Figure 6 #############
# Panel A
# Topic 2.6: Guidelines
p_rationale_guidelines <- plot_combined_questions(data, 
                        meta, 
                        combined_questions = "Q20",
                        sample_sizes = sample_sizes,
                        combine_ab = FALSE, 
                        colors = "#D55E00",
                        title_plot = "Why was no research guideline used?",
                        y_max = 80,
                        wrap_width = 80)

p_rationale_guidelines <- p_rationale_guidelines + theme(plot.margin = margin(10, 10, 10, 30))

# Panel B
# Topic 2.7: Preregistration
p_rationale_prereg <- plot_combined_questions(data, 
                        meta, 
                        combined_questions = "Q22",
                        sample_sizes = sample_sizes,
                        combine_ab = FALSE, 
                        colors = "#D55E00",
                        title_plot = "Why wasn't the simulation study preregistered?",
                        y_max = 80,
                        wrap_width = 80) 

p_rationale_prereg <- p_rationale_prereg + theme(plot.margin = margin(6, 10, 10, 38))

# Panel C
# Topic 2.8: Open code
p_rationale_codesharing <- plot_combined_questions(data, 
                        meta, 
                        combined_questions = "Q24",
                        sample_sizes = sample_sizes,
                        combine_ab = FALSE, 
                        colors = "#D55E00",
                        title_plot = "Why is not all code openly available?",
                        y_max = 80,
                        wrap_width = 80)

p_rationale_codesharing <- p_rationale_codesharing + theme(plot.margin = margin(6, 10, 10, 36))


# Panel D
# Topic 2.9: Reproducibility
p_rationale_reproducibility <- plot_combined_questions(data, 
                        meta, 
                        combined_questions = "Q25",
                        sample_sizes = sample_sizes,
                        combine_ab = FALSE, 
                        colors = "#D55E00",
                        title_plot = "Which measures were taken for computational reproducibility?",
                        y_max = 80,
                        wrap_width = 40)

p_rationale_reproducibility <- p_rationale_reproducibility + theme(plot.margin = margin(6, 10, 10, 30))

arrange_fig6 <- ggarrange(p_rationale_guidelines,
                          p_rationale_prereg,
                          p_rationale_codesharing,
                          p_rationale_reproducibility, nrow = 4, ncol = 1, labels = "AUTO")

ggsave("Figure_6.png", plot = arrange_fig6, width = 12*1.5, height = 20.05*1.5, units = "cm", dpi = 300)

```

### 4.3 Combined Plot Reporting (\@ Lieke dit blok mag je overslaan)

<!--# This block should go to analyses somewhere and must be cleaned up -->

```{r}







## How many participants engaged in not reporting a result for any of the elements?
data_not_reported <- data %>%
  filter(conditions == 0 | methods == 0 | perfmeas == 0)

any_not_reported <- nrow(data_not_reported)/221

## How many participants engaged in split reporting a results for any of the elements?
data_split_reported <- data %>%
  filter(conditions == 2 | methods == 2 | perfmeas == 2)

any_split_reported <- nrow(data_split_reported)/221

total_any_selective_reported <- (nrow(data_not_reported) + nrow(data_split_reported))/221


# NOTE: check if we keep this or not
## How many participants engaged in either focusing on significant results (6), conclusion alignment (8), or a specific method (10)
# Sample sizes for neutral and non-neutral groups that engaged in selective reporting for:
# Conditions
neutral_n_conditions <- data %>%
  filter(new_method == 0 & (Q7a_1 == 1 |
           Q7a_1 == 0 |
           Q7b_1 == 1 |
           Q7b_1 == 0))

non_neutral_n_conditions <- data %>%
  filter(new_method == 1 & (Q7a_1 == 1 |
           Q7a_1 == 0 |
           Q7b_1 == 1 |
           Q7b_1 == 0))
           

# Questionable selective reporting neutral group
qrp_condition_neutral <- neutral_n_conditions %>%
  filter(Q7a_6 == 1 |
         Q7b_6 == 1 |
           Q7a_8 == 1 |
           Q7b_8 == 1 |
           Q7a_10 == 1 |
           Q7b_10 == 1 )


# QRP selective reporting non-neutral group
qrp_condition_non_neutral <- non_neutral_n_conditions %>%
  filter(Q7a_6 == 1 |
         Q7b_6 == 1 |
           Q7a_8 == 1 |
           Q7b_8 == 1 |
           Q7a_10 == 1 |
           Q7b_10 == 1 )

# Percentages
neutral_conditions <- nrow(qrp_condition_neutral)/nrow(neutral_n_conditions) # .1363636363
non_neutral_conditions <- nrow(qrp_condition_non_neutral)/nrow(non_neutral_n_conditions) # .210526


# Sample sizes for neutral and non-neutral groups that engaged in selective reporting for:
# methods
neutral_n_methods <- data %>%
  filter(new_method == 0 & (Q10a_1 == 1 |
           Q10a_1 == 0 |
           Q10b_1 == 1 |
           Q10b_1 == 0))

non_neutral_n_methods <- data %>%
  filter(new_method == 1 & (Q10a_1 == 1 |
           Q10a_1 == 0 |
           Q10b_1 == 1 |
           Q10b_1 == 0))
           

# Questionable selective reporting neutral group
qrp_methods_neutral <- neutral_n_methods %>%
  filter(Q10a_6 == 1 |
         Q10b_6 == 1 |
           Q10a_8 == 1 |
           Q10b_8 == 1 |
           Q10a_10 == 1 |
           Q10b_10 == 1 )


# QRP selective reporting non-neutral group
qrp_methods_non_neutral <- non_neutral_n_methods %>%
  filter(Q10a_6 == 1 |
         Q10b_6 == 1 |
           Q10a_8 == 1 |
           Q10b_8 == 1 |
           Q10a_10 == 1 |
           Q10b_10 == 1 )

# Percentages
neutral_methods <- nrow(qrp_methods_neutral)/nrow(neutral_n_methods) # 0.1428571
non_neutral_methods <- nrow(qrp_methods_non_neutral)/nrow(non_neutral_n_methods) # .25


# Sample sizes for neutral and non-neutral groups that engaged in selective reporting for:
# Performance Measures
neutral_n_perfmeas <- data %>%
  filter(new_method == 0 & (Q13a_1 == 1 |
           Q13a_1 == 0 |
           Q13b_1 == 1 |
           Q13b_1 == 0))

non_neutral_n_perfmeas <- data %>%
  filter(new_method == 1 & (Q13a_1 == 1 |
           Q13a_1 == 0 |
           Q13b_1 == 1 |
           Q13b_1 == 0))
           

# Questionable selective reporting neutral group
qrp_perfmeas_neutral <- neutral_n_perfmeas %>%
  filter(Q13a_6 == 1 |
         Q13b_6 == 1 |
           Q13a_8 == 1 |
           Q13b_8 == 1 |
           Q13a_10 == 1 |
           Q13b_10 == 1 )


# QRP selective reporting non-neutral group
qrp_perfmeas_non_neutral <- non_neutral_n_perfmeas %>%
  filter(Q13a_6 == 1 |
         Q13b_6 == 1 |
           Q13a_8 == 1 |
           Q13b_8 == 1 |
           Q13a_10 == 1 |
           Q13b_10 == 1 )

# Percentages
neutral_perfmeas <- nrow(qrp_perfmeas_neutral)/nrow(neutral_n_perfmeas) # 0.1111111
non_neutral_perfmeas <- nrow(qrp_perfmeas_non_neutral)/nrow(non_neutral_n_perfmeas) #0.3333333


combined_questions <- c("Q7a", "Q7b", "Q10a", "Q10b", "Q13a", "Q13b")

cols <- meta %>%
  filter(question_group %in% combined_questions) %>%
  pull(question_code) %>%
  unique()

n_at_least_one <- data %>%
  mutate(
    any_answered = rowSums(
      across(
        all_of(cols),
        ~ !is.na(.) & !. %in% c(-99, 999)
      ) 
    )) %>%
  filter(any_answered > 0)


# Datasets containing everyone that engaged in selective reporting at least one time for neutral studies
neutral_at_least_one <- n_at_least_one %>%
  filter(new_method == 0)

# Datasets containing everyone that engaged in selective reporting at least one time for non-neutral studies
non_neutral_at_least_one <- n_at_least_one %>%
  filter(new_method == 1)


neutral <- neutral_at_least_one %>%
  filter(Q7a_6 == 1 |
         Q7b_6 == 1 |
           Q7a_8 == 1 |
           Q7b_8 == 1 |
           Q7a_10 == 1 |
           Q7b_10 == 1 |
           Q10a_6 == 1 |
         Q10b_6 == 1 |
           Q10a_8 == 1 |
           Q10b_8 == 1 |
           Q10a_10 == 1 |
           Q10b_10 == 1 |
           Q13a_6 == 1 |
         Q13b_6 == 1 |
           Q13a_8 == 1 |
           Q13b_8 == 1 |
           Q13a_10 == 1 |
           Q13b_10 == 1)

non_neutral <- non_neutral_at_least_one %>%
  filter(Q7a_6 == 1 |
         Q7b_6 == 1 |
           Q7a_8 == 1 |
           Q7b_8 == 1 |
           Q7a_10 == 1 |
           Q7b_10 == 1 |
           Q10a_6 == 1 |
         Q10b_6 == 1 |
           Q10a_8 == 1 |
           Q10b_8 == 1 |
           Q10a_10 == 1 |
           Q10b_10 == 1 |
           Q13a_6 == 1 |
         Q13b_6 == 1 |
           Q13a_8 == 1 |
           Q13b_8 == 1 |
           Q13a_10 == 1 |
           Q13b_10 == 1)

# How many participants in neutral studies engaged in questionable selective reporting at least once:
nrow(neutral)/nrow(neutral_at_least_one) # = .111111

# How many participants in non-neutral studies engaged in questionable selective reporting at least once:
nrow(non_neutral)/nrow(non_neutral_at_least_one) # = .2891566


```

### 4.4 Plots split by variable

```{r}

plot_combined_questions_grouped <- function(
  data,
  metadata,
  combined_questions,
  split_var = NULL,
  legend_labels = c("Neutral", "Non-neutral"), 
  title_plot = combined_questions,
  combine_ab = FALSE,
  wrap_width = 50,
  colors = c("#0072B2", "#D55E00"), 
  y_max = 100,
  show_legend = TRUE
) {

  # ---- 1. Select & Map Metadata ----
  if (combine_ab) {
    question_map <- tibble(
      combined = rep(combined_questions, each = 2),
      question_group = paste0(rep(combined_questions, each = 2), c("a", "b"))
    )
    
    meta_sel <- metadata %>%
      inner_join(question_map, by = "question_group") %>%
      arrange(combined, order)
    
  } else {
    
    meta_sel <- metadata %>%
      filter(question_group %in% combined_questions) %>%
      mutate(combined = question_group) %>%
      arrange(combined, order)
  }

  # ---- 2. Calculate Sample Sizes per Group ----
  plot_sample_sizes <- meta_sel %>%
    distinct(combined, question_group, question_code) %>%
    group_by(combined, question_group) %>%
    group_modify(~ {
      current_code <- .x$question_code[1]
      data %>%
        # Ensure split_var is a factor here
        mutate(across(all_of(split_var), as.factor)) %>% 
        group_by(across(all_of(split_var))) %>%
        summarise(
          sample_size = sum(!is.na(.data[[current_code]]) & 
                            .data[[current_code]] != -99 & 
                            .data[[current_code]] != 999),
          .groups = "drop"
        )
    }) %>%
    ungroup()

  if (combine_ab) {
    plot_sample_sizes <- plot_sample_sizes %>%
      group_by(across(all_of(c(split_var, "combined")))) %>%
      summarise(sample_size = sum(sample_size), .groups = "drop")
  } else {
    plot_sample_sizes <- plot_sample_sizes %>%
      select(all_of(c(split_var, "combined", "sample_size")))
  }

  # ---- 3. Count Selections ----
  relevant_codes <- unique(meta_sel$question_code)
  long_data <- data %>%
    select(all_of(c(split_var, relevant_codes))) %>%
    # Ensure split_var is a factor here as well
    mutate(across(all_of(split_var), as.factor)) %>%
    pivot_longer(
      cols = all_of(relevant_codes),
      names_to = "question_code",
      values_to = "value"
    )

  if (combine_ab) {
    long_data <- long_data %>% filter(value == 1)
  } else {
    long_data <- long_data %>% filter(!is.na(value))
  }

  counts <- long_data %>%
    inner_join(meta_sel, by = c("question_code", "value")) %>%
    group_by(across(all_of(c(split_var, "combined", "short_label", "order")))) %>%
    summarise(freq = n(), .groups = "drop")

  # ---- 4. Percentages & Factors ----
  plot_data <- counts %>%
    complete(
      nesting(combined, short_label, order), 
      !!sym(split_var), 
      fill = list(freq = 0)
    ) %>%
    left_join(plot_sample_sizes, by = c(split_var, "combined")) %>%
    mutate(
      pct = ifelse(is.na(sample_size) | sample_size == 0, 0, 100 * freq / sample_size),
      label = sprintf("%.1f%% (%d)", pct, freq),
      short_label = factor(
        short_label, 
        levels = meta_sel %>% arrange(order) %>% distinct(short_label) %>% pull(short_label)
      )
    )

  # ---- 5. Plot ----
  ggplot(
    plot_data, 
    aes(
      x = fct_rev(short_label), 
      y = pct, 
      fill = .data[[split_var]]
      )
    ) +
    geom_col(
      position = position_dodge(width = 0.8), 
      width = 0.8, 
      alpha = 0.8, 
      color = "black", 
      linewidth = 0.3
      ) +
    geom_text(
      aes(label = label), 
      position = position_dodge(width = 0.8), 
      hjust = -0.1, 
      size = 3
      ) +
    coord_flip(
    ) +
    scale_y_continuous(
      limits = c(0, y_max), 
      expand = expansion(mult = c(0, 0.2))
      ) +
    scale_fill_manual(
      values = colors, 
      labels = legend_labels, 
      name = ""
      ) +
    scale_x_discrete(
      labels = ~ stringr::str_wrap(.x, wrap_width)
      ) +
    labs(
      x = NULL, 
      y = "Percentage", 
      title = if (!is.null(title_plot)) stringr::str_wrap(title_plot, wrap_width)
      ) +
    theme_bw(
    ) +
    theme(plot.title = element_text(hjust = 0.5, size = 10, face = "bold"),
          axis.text.y = element_text(face = "bold"),
          legend.position = "bottom", plot.margin = margin(10, 10, 10, 30)
          )
}
```

### 4.5 Plot a question

-   NOTE: Check if Q14 and Q15 should also become a combined plot, then add new variable just as with conditions/methods/performance measures

```{r}
# Generating a PDF with plots split by new_method
# NOTE: titles need to be added correctly

plot_list <- list()

for (i in 1:length(all_vars)) {
  
  # Extract the title from metadata for the current question
  current_title <- meta %>%
    filter(question_group == all_vars[i]) %>%
    slice(1) %>%
    pull(item)
  
  # Call the function using the extracted title
  p <- plot_combined_questions_grouped(
    data = data,
    metadata = meta,
    combine_ab = all_vars[i] %in% vars_to_plot_ab,
    combined_questions = all_vars[i],
    split_var = "new_method",
    wrap_width = 50,
    title_plot = paste0(all_vars[i], ": ", current_title)
  )
  plot_list[[i]] <- p + theme(plot.margin = margin(1, 1, 1, 1, "cm"))
}

# Add plots to object to save
multipage_plot <- marrangeGrob(plot_list, nrow = 2, ncol = 2) # NOTE: Check how many plots per page works well
# Generate PDF with plots
ggsave("Questionnaire_Results_Full.pdf", multipage_plot, width = 8.5, height = 11)


########## Plots split by aim ##################
# NOTE: not done yet

plot_combined_questions_grouped(
    data = data,
    metadata = meta,
    combine_ab = FALSE,
    combined_questions = c("Q12"),
    legend_labels = c("New method compared", "New method not compared", "Existing method(s)", "Other"),
    colors = c("red", "blue", "grey", "orange"),
    split_var = "Q2" #split by aim
)
```
